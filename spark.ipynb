{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version\n",
      "Apache Spark version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sparknlp \n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\")\n",
    "sparknlp.version()\n",
    "print(\"Apache Spark version\")\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages (1.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages (from pandas) (1.18.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp==2.5.0 in /home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages (2.5.0)\n",
      "Processing /home/amin/.cache/pip/wheels/06/e8/1c/37ed9ed9f29a039ca301c5bf9810128334a69fde67cf5488ff/pyspark-2.4.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: py4j==0.10.7 in /home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages (from pyspark==2.4.4) (0.10.7)\n",
      "Installing collected packages: pyspark\n",
      "  Attempting uninstall: pyspark\n",
      "    Found existing installation: pyspark 2.4.5\n",
      "    Can't uninstall 'pyspark'. No files were found to uninstall.\n",
      "Successfully installed pyspark-2.4.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spark-nlp==2.5.0 pyspark==2.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7810c4e860>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets = spark.read.format(\"csv\").option(\"inferSchema\", 'true').option(\"header\", 'false').option(\"sep\", \",\").load('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[_c0: int, _c1: bigint, _c2: string, _c3: string, _c4: string, _c5: string]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tweets.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col \n",
    "raw_tweets = raw_tweets.select(col('_c0'),col('_c5'))\\\n",
    ".withColumnRenamed('_c0', 'Label')\\\n",
    ".withColumnRenamed('_c5', 'Text')\\\n",
    ".dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1583691"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|Label|                Text|\n",
      "+-----+--------------------+\n",
      "|    0|I feel like a com...|\n",
      "|    0|@KishoreK this is...|\n",
      "|    0|@InYourEyes2410 I...|\n",
      "|    0|       A little sad |\n",
      "|    0|I'm off too bed. ...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_tweets.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import SQLTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler().setInputCol(\"Text\").setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentences\").setUseAbbreviations(True)\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"sentences\"]).setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer().setInputCols([\"token\"]).setOutputCol(\"normal\")\n",
    "\n",
    "stop_word = StopWordsCleaner().setInputCols([\"normal\"]).setOutputCol('clean')\n",
    "\n",
    "stemmer = Stemmer().setInputCols(['clean']).setOutputCol('stem')\n",
    "\n",
    "glove_embeddings = WordEmbeddingsModel().pretrained().setInputCols([\"document\",\"stem\"]).setOutputCol(\"embeddings\")\n",
    "\n",
    "embed_sentence = SentenceEmbeddings().setInputCols([\"document\",\"embeddings\"]).setOutputCol(\"sent_embed\")\\\n",
    ".setPoolingStrategy('AVERAGE')\n",
    "\n",
    "embeddings_finisher = EmbeddingsFinisher().setInputCols('sent_embed').setOutputCols('finished_sentence_embeddings')\n",
    "\n",
    "#explodeVectors = SQLTransformer(statement = \n",
    "                               #\"SELECT EXPLODE(finished_sentence_embeddings) AS features, FROM__THIS__\")\n",
    "\n",
    "#finisher = Finisher().setInputCols(['stem']).setOutputCols('ntokens')\\\n",
    "#.setOutputAsArray(True).setCleanAnnotations(True)\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    " document_assembler, \n",
    " sentenceDetector,\n",
    " tokenizer,\n",
    " normalizer,\n",
    " stop_word,   \n",
    " stemmer,\n",
    " glove_embeddings,\n",
    " embed_sentence,\n",
    " embeddings_finisher,\n",
    " #explodeVectors,\n",
    " ])\n",
    "\n",
    "pipelineModel = nlpPipeline.fit(raw_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583691\n"
     ]
    }
   ],
   "source": [
    "processed = pipelineModel.transform(raw_tweets)\n",
    "print(processed.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sentences=[Row(annotatorType='document', begin=0, end=28, result='I feel like a complete idiot.', metadata={'sentence': '0'}, embeddings=[]), Row(annotatorType='document', begin=30, end=90, result=\"I'm the only one who doesn't get how this shit works  help me\", metadata={'sentence': '1'}, embeddings=[])])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.select(\"sentences\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "data = processed.withColumn(\"features\", explode(processed.finished_sentence_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=[-0.07529754191637039, 0.13422273099422455, 0.3415910601615906, -0.3557145297527313, -0.20880037546157837, 0.03789282217621803, -0.2928003668785095, 0.042057182639837265, 0.14446181058883667, -0.09094779193401337, 0.12380874156951904, 0.09928963333368301, 0.23074579238891602, -0.12493426352739334, -0.09839699417352676, 0.0022225461434572935, 0.10741699486970901, 0.27960482239723206, -0.13010726869106293, 0.392767071723938, 0.1709136813879013, 0.3062072694301605, -0.12738752365112305, -0.2340545505285263, 0.03396772965788841, 0.11415155231952667, -0.25131019949913025, -0.30153873562812805, 0.2542422115802765, -0.21709389984607697, -0.2400454580783844, 0.27437493205070496, 0.09648680686950684, 0.11824581027030945, 0.011344101279973984, 0.32770535349845886, -0.1969478279352188, 0.2630782723426819, 0.06568169593811035, -0.23244719207286835, -0.11291618645191193, 0.06451380997896194, -0.15443290770053864, -0.2522612512111664, -0.47303545475006104, -0.2834317982196808, -0.11356690526008606, -0.11450908333063126, -0.010603147558867931, -0.38632088899612427, -0.4070611000061035, 0.06916110217571259, 0.1002240926027298, 0.5302954316139221, -0.3482910096645355, -1.2933892011642456, 0.2444532811641693, 0.005733002442866564, 0.9128145575523376, 0.11456000804901123, 0.13368664681911469, 0.62567538022995, -0.5630002617835999, -0.08236809074878693, 0.4934382140636444, 0.21257056295871735, 0.4395737648010254, 0.16571937501430511, -0.08030926436185837, -0.4172017276287079, 0.0743967741727829, -0.35875189304351807, 0.0011889879824593663, -0.2819731533527374, 0.07491854578256607, 0.22342754900455475, 0.042412105947732925, -0.0004222663992550224, -0.1766051948070526, -0.0943160131573677, 0.33348509669303894, -0.08055582642555237, -0.4142836332321167, 0.02110808901488781, -1.0313735008239746, -0.0037682584952563047, 0.07508073002099991, -0.10354065150022507, -0.3769572377204895, -0.2617863714694977, -0.08381599932909012, -0.14101064205169678, 0.1013716459274292, -0.044553492218256, 0.01708543859422207, -0.0508410707116127, 0.07708018273115158, -0.24256004393100739, 0.21314691007137299, 0.19987855851650238])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select('features').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from org.apache.spark.ml.linal import Vector, Vectors\n",
    "from pyspark.ml.linalg import Vector, Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "@udf(returnType = VectorUDT())\n",
    "def convertToVectorUDF(matrix):\n",
    "    return Vectors.dense(matrix.toArray.map(_.toDouble))\n",
    "\n",
    "\n",
    "# Now let's explode the sentence_embeddings column and have a new feature column for Spark ML\n",
    "\n",
    "#data = data.select('explode(\"sent_embed.embeddings\").alias(\"sentence_embedding\")').withColumn(\"features\", convertToVectorUDF(\"sentence_embedding\"))  \n",
    "data = data.withColumn(\"features1\", convertToVectorUDF(\"features\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-480b2b2cab8c>\", line 1, in <module>\n",
      "    data.select('features').take(2)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1324, in select\n",
      "    jdf = self._jdf.select(self._jcols(*cols))\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1118, in _jcols\n",
      "    return self._jseq(cols, _to_java_column)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1105, in _jseq\n",
      "    return _to_seq(self.sql_ctx._sc, cols, converter)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in _to_seq\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 65, in <listcomp>\n",
      "    cols = [converter(c) for c in cols]\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 47, in _to_java_column\n",
      "    jcol = _create_column_from_name(col)\n",
      "  File \"/home/amin/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\", line 40, in _create_column_from_name\n",
      "    return sc._jvm.functions.col(name)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1649, in __getattr__\n",
      "    \"\\n\" + proto.END_COMMAND_PART)\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:45055)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amin/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:45055)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-480b2b2cab8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \"\"\"\n\u001b[0;32m-> 1324\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m_jcols\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sort_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m_jseq\u001b[0;34m(self, cols, converter)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;34m\"\"\"Return a JVM Seq of Columns from a list of Column or names\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m_to_seq\u001b[0;34m(sc, cols, converter)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mjcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mjcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_column_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         raise TypeError(\n",
      "\u001b[0;32m~/Downloads/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m_create_column_from_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_create_column_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \"\\n\" + proto.END_COMMAND_PART)\n\u001b[0m\u001b[1;32m   1650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUCCESS_PACKAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mJavaPackage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjvm_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    981\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \"\"\"\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    936\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sparknlp/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:45055)"
     ]
    }
   ],
   "source": [
    "data.select('features').take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = processed.randomSplit(weights=[0.7,0.3], seed = 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.count())\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(train)\n",
    "\n",
    "# get training summary used for eval metrics and other params\n",
    "lrTrainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test data\n",
    "lrPredictions = lrModel.transform(testData)\n",
    "\n",
    "# display predictions\n",
    "lrPredictions.select(\"label\", \"prediction\", \"probability\").limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
