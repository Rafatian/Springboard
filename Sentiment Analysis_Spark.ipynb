{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version\n",
      "Apache Spark version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sparknlp \n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\")\n",
    "sparknlp.version()\n",
    "print(\"Apache Spark version\")\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f93e4c4e860>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets = spark.read.format(\"csv\").option(\"inferSchema\", 'true').option(\"header\", 'false').option(\"sep\", \",\").load('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[_c0: int, _c1: bigint, _c2: string, _c3: string, _c4: string, _c5: string]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tweets.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col \n",
    "raw_tweets = raw_tweets.select(col('_c0'),col('_c5'))\\\n",
    ".withColumnRenamed('_c0', 'Target')\\\n",
    ".withColumnRenamed('_c5', 'Text')\\\n",
    ".dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1583691"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|Target|                Text|\n",
      "+------+--------------------+\n",
      "|     0|I feel like a com...|\n",
      "|     0|@KishoreK this is...|\n",
      "|     0|@InYourEyes2410 I...|\n",
      "|     0|       A little sad |\n",
      "|     0|I'm off too bed. ...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_tweets.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler().setInputCol(\"Text\").setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentences\").setUseAbbreviations(True)\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"sentences\"]).setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer().setInputCols([\"token\"]).setOutputCol(\"normal\")\n",
    "\n",
    "stop_word = StopWordsCleaner().setInputCols([\"normal\"]).setOutputCol('clean')\n",
    "\n",
    "stemmer = Stemmer().setInputCols(['clean']).setOutputCol('stem')\n",
    "\n",
    "finisher = Finisher().setInputCols([\"stem\"]).setOutputCols(\"token_features\")\n",
    "\n",
    "CountVectors = CountVectorizer(inputCol= \"token_features\", outputCol= \"features\", vocabSize = 10000, minDF= 5)\n",
    "\n",
    "label_stringIDx = StringIndexer(inputCol= 'Target', outputCol=\"label\")\n",
    "\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    " document_assembler, \n",
    " sentenceDetector,\n",
    " tokenizer,\n",
    " normalizer,\n",
    " stop_word,   \n",
    " stemmer,\n",
    " finisher,\n",
    " CountVectors,\n",
    " label_stringIDx\n",
    " ])\n",
    "\n",
    "pipelineModel = nlpPipeline.fit(raw_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583691\n"
     ]
    }
   ],
   "source": [
    "processed = pipelineModel.transform(raw_tweets)\n",
    "print(processed.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(10000, {0: 1.0, 2: 1.0, 5: 1.0, 6: 1.0, 18: 1.0, 23: 1.0, 116: 1.0, 144: 1.0, 280: 1.0, 521: 1.0, 1728: 1.0}))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.select(\"features\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = processed.randomSplit(weights=[0.7,0.3], seed = 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109771\n",
      "473920\n"
     ]
    }
   ],
   "source": [
    "print(train.count())\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Target: integer (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- token_features: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(train)\n",
    "\n",
    "# get training summary used for eval metrics and other params\n",
    "lrTrainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.30657493332798763, 0.6934250666720123]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.6044232531691004, 0.39557674683089966]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.5228333362444512, 0.4771666637555487]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.015941219674955865, 0.9840587803250442]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.8383991946981377, 0.1616008053018623]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.6573956471613437, 0.34260435283865637]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.04602579040946332, 0.9539742095905368]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.014705683858720286, 0.9852943161412797]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.33097732856222606, 0.6690226714377739]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.6193618941371545, 0.3806381058628454]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  prediction                                 probability\n",
       "0    1.0         1.0   [0.30657493332798763, 0.6934250666720123]\n",
       "1    1.0         0.0   [0.6044232531691004, 0.39557674683089966]\n",
       "2    1.0         0.0    [0.5228333362444512, 0.4771666637555487]\n",
       "3    1.0         1.0  [0.015941219674955865, 0.9840587803250442]\n",
       "4    1.0         0.0    [0.8383991946981377, 0.1616008053018623]\n",
       "5    1.0         0.0   [0.6573956471613437, 0.34260435283865637]\n",
       "6    1.0         1.0   [0.04602579040946332, 0.9539742095905368]\n",
       "7    1.0         1.0  [0.014705683858720286, 0.9852943161412797]\n",
       "8    1.0         1.0   [0.33097732856222606, 0.6690226714377739]\n",
       "9    1.0         0.0    [0.6193618941371545, 0.3806381058628454]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on test data\n",
    "lrPredictions = lrModel.transform(test)\n",
    "\n",
    "# display predictions\n",
    "lrPredictions.select(\"label\", \"prediction\", \"probability\").limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7759629349395232"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol= \"prediction\")\n",
    "\n",
    "evaluator.evaluate(lrPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_true = lrPredictions.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = lrPredictions.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[190729,  46634],\n",
       "       [ 59459, 177098]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_true.label,y_pred.prediction)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.80      0.78    237363\n",
      "         1.0       0.79      0.75      0.77    236557\n",
      "\n",
      "    accuracy                           0.78    473920\n",
      "   macro avg       0.78      0.78      0.78    473920\n",
      "weighted avg       0.78      0.78      0.78    473920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true.label,y_pred.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
